defaults:
# dataset
- dataset/doughnet@dataset.train
- dataset/doughnet@dataset.val
- dataset/doughnet@dataset.test
- dataset/doughnet@dataset.real
# model
- encoder/rbf@model.encoder
- transformer/cross_attn@model.aggregate
- transformer/self_attn@model.process
- transformer/cond_attn@model.condition
- transformer/cross_attn@model.interpolate
- transformer/cross_attn@model.segment
- _self_

logging:
  project: doughnet

dimensions:
  input_dim: 4  # [3: xyz, 4: xyzl]
  num_query_in: ${eval:'${dataset.n_points} // 4'}  # subsample of observation = number of tokens
  latent_dim: 512  # default: 384
  num_query_out: ${eval:'${dataset.n_points} * 4'}  # queried points = number of predictions
  output_dim: 1  # occupancy (per part)
  num_parts: 5
  num_genus: 3
augmentation:
  # in dataloader
  mirror: True
  scale: [0.75, 1.25]  # set to [1.0, 1.0] to disable
  # in pipeline
  render:
    # note: in our simulation units, 0.1 = 2cm -> 0.05 = 1cm -> 5.0 = 1m ==> x5 from extrinsics in meters to our units
    meter_to_unit: 5.0
    unit_to_meter: 0.2
    # for random extrinsics
    max_dist: 0.6  # in meters, approximately what we see in the real world (mean for cam0=0.6278, cam1=0.5865)
    cam_t_std: 0.01  # in meters, rounded up from real observations (std for cam0=0.0094, cam1=0.0086)
    cam_r_std: 1.0  # in degrees, we take a random rotation vector and rotate by this magnitude
    # dataset extrinsics
    cam_t_mean: [0.058935660461105016, 0.3974398951001392, 0.40259997885181237]  # in meters
    cam_q_mean: [0.031946957916656735, 0.9257826916263031, -0.37656636278532485, -0.010177140249599106]
    # dataset intrinsics
    width: 1920
    height: 1080
    fx: 1386.8900146484375
    fy: 1385.550048828125
    cx: 971.7710571289062
    cy: 530.1279907226562
    render_downsample: 5  # downsample factor for rendering, set to 1 to disable -- nvdiffrast requires width and height to be divisible by 8 -> [1, 3, 5] work
    # augmentation
    image_noise: True  # Kinect-style noise as used in BlenderProc
    perlin_noise: False  # Perlin noise to get low-frequency displacement
    perlin_noise_res: 12  # in pixels, lower res creates more low-frequency noise -- max 12 for downsample=5
    perlin_noise_scale: 0.005  # in meters
    voxel_size: 0.005  # in units, same for synthetic and real to reduce domain shift
# dataset
dataset:
  n_points: 1024
  next_frames: 0  # 0: cur, 1: cur -> nxt, 2: cur -> nxt -> nxtnxt
  next_frame_offset: 5  # between cur and nxt
  train:
    subset: train
    bs: ${training.bs}
    augmentation: ${augmentation}
    use_small: False  # only use small dataset for debugging and ablations
  val:
    subset: val_test
    bs: ${eval:'1 if ${settings.val_multi} else 8'}  # grid takes a lot of memory
    augmentation: ${augmentation}
    use_small: True  # always use small dataset
  test:
    subset: val_test
    bs: 1
    augmentation: ${augmentation}
    use_small: False  # never use small dataset
  real:
    subset: real
    bs: 1
    augmentation: ${augmentation}
    use_small: False  # never use small dataset
# training
training:
  epochs: 30
  grad_norm_clip : 0.01  # <= 0 to disable; 0.01 seems more stable with little/no performance loss
  bs: ${eval:'[54,32,12][${dataset.next_frames}]'}
  seed: 0
optimizer:
  type: AdamW
  kwargs:
    lr : 0.0005  # default: 0.0005
    weight_decay : 2.5e-5  # will be divided by lr; default: 2.5*1e-5 (/ 5e-4 = 0.05)
    betas: [0.9, 0.95]  # default: [0.9, 0.999]
scheduler:
  type: CosLR
  kwargs:
    epochs: ${training.epochs}
    initial_epochs : 3
    lr_min: 1e-6
    warmup_lr_init: 1e-6

loss:
  # meta
  no_outlier_perm: True  # True: outliers always assumed to be in first mask, rest may be permuted
  num_parts: ${dimensions.num_parts}
  # pipeline
  get_rec_cur: ${eval:'${loss.w_rec_cur} > 0 or ${loss.w_lat_nxt} > 0 or ${loss.w_pre_nxt} > 0'}
  get_rec_nxt: ${eval:'${loss.w_rec_nxt} > 0 or ${loss.w_lat_nxt} > 0'}
  get_rec_nxtnxt: ${eval:'${loss.w_rec_nxtnxt} > 0 or ${loss.w_lat_nxtnxt} > 0'}
  get_pre_nxt: ${eval:'${loss.w_pre_nxt} > 0 or ${loss.w_lat_nxt} > 0 or ${loss.w_pre_nxtnxt} > 0'}
  get_pre_nxtnxt: ${eval:'${loss.w_pre_nxtnxt} > 0 or ${loss.w_lat_nxtnxt} > 0'}
  get_top: ${eval:'${loss.w_top} > 0'}

model:
  condition:
    ee_shape: 'both'  # 'observed' for current, 'target' for next, or 'both'
  emb_part:
    type: 'mlp'  # 'none', 'fc', 'mlp'
  high_level_token: 'mean'  # 'none', 'mean', 'max'
